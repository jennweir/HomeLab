---
- name: Playbook to install k8s on raspberry pis
  hosts: pis
  become: yes
  gather_facts: no
  tasks:
    - name: Updates package cache, performs system upgrade, and cleans up unnecessary package files
      ansible.builtin.apt:
        update_cache: yes
        upgrade: dist
        cache_valid_time: 3600
        autoclean: yes
        autoremove: yes

    - name: Reboot the system to apply updates
      ansible.builtin.reboot:
        msg: "Rebooting after performing upgrade and cleaning files"
        connect_timeout: 5
        reboot_timeout: 300
        pre_reboot_delay: 0
        post_reboot_delay: 30

    - name: Check whether package dphys-swapfile is installed
      ansible.builtin.package_facts:
        manager: auto

    - name: Turn off "dphys-swapfile"
      ansible.builtin.command: dphys-swapfile swapoff
      when: "'dphys-swapfile' in ansible_facts.packages"

    - name: Uninstall "dphys-swapfile"
      ansible.builtin.command: dphys-swapfile uninstall
      when: "'dphys-swapfile' in ansible_facts.packages"

    - name: Remove and purge "dphys-swapfile" package
      ansible.builtin.apt:
        pkg: dphys-swapfile
        state: absent
        purge: yes
        autoclean: yes
        autoremove: yes
      when: "'dphys-swapfile' in ansible_facts.packages"

    - name: Ensure zram-generator config directory exists
      ansible.builtin.file:
        path: /etc/systemd/zram-generator.conf.d
        state: directory
        mode: '0755'

    - name: Disable zram swap via override config
      ansible.builtin.copy:
        dest: /etc/systemd/zram-generator.conf.d/disable-zram.conf
        mode: '0644'
        content: |
          [zram0]
          enabled = false

    - name: Reload systemd to pick up zram changes
      ansible.builtin.command: systemctl daemon-reload

    - name: Disable zram setup service
      ansible.builtin.systemd:
        name: systemd-zram-setup@zram0.service
        enabled: no

    - name: Stop zram setup service
      ansible.builtin.systemd:
        name: systemd-zram-setup@zram0.service
        state: stopped
        masked: yes

    - name: Turn off swap
      ansible.builtin.command: swapoff -a

    - name: Ensure no swap entries remain in /etc/fstab
      ansible.builtin.replace:
        path: /etc/fstab
        regexp: '^\S+\s+\S+\s+swap\s+'
        replace: '# swap disabled for Kubernetes'

    - name: Reboot to fully disable zram
      ansible.builtin.reboot:
        msg: "Rebooting to disable zram swap"
        reboot_timeout: 120

    - name: Append cgroup settings to /boot/firmware/cmdline.txt
      ansible.builtin.lineinfile:
        path: /boot/firmware/cmdline.txt
        regexp: '^(.*rootwait.*)$'
        line: '\1 cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1'
        backrefs: yes

    - name: Reboot the system to apply cgroup changes
      ansible.builtin.reboot:
        msg: "Rebooting after cgroup configuration"
        connect_timeout: 5
        reboot_timeout: 300
        pre_reboot_delay: 0
        post_reboot_delay: 30

    - name: Install containerd as the container runtime
      ansible.builtin.apt:
        pkg:
          - containerd
          - containernetworking-plugins

    - name: Configure containerd
      ansible.builtin.copy:
        content: |
          version = 2
          [plugins]
            [plugins."io.containerd.grpc.v1.cri"]
              [plugins."io.containerd.grpc.v1.cri".containerd]
                [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
                  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                    runtime_type = "io.containerd.runc.v2"
                    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                      SystemdCgroup = true
        dest: /etc/containerd/config.toml
        backup: yes
        owner: root
        group: root
        mode: '0644'

    - name: Create k8s.conf file in the /etc/modules-load.d directory
      ansible.builtin.copy:
        content: |
          overlay
          br_netfilter
        dest: /etc/modules-load.d/k8s.conf
        backup: yes
        owner: root
        group: root
        mode: '0644'

    - name: Load overlay
      ansible.builtin.command: modprobe overlay

    - name: Load br_netfilter
      ansible.builtin.command: modprobe br_netfilter

    - name: Create k8s.conf file in /etc/sysctl.d directory
      ansible.builtin.copy:
        content: |
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
        dest: /etc/sysctl.d/k8s.conf
        backup: yes
        owner: root
        group: root
        mode: '0644'

    - name: Run sysctl --system
      ansible.builtin.command: sysctl --system

    - name: Install apt-transport-https ca-certificates
      ansible.builtin.apt:
        pkg:
          - apt-transport-https
          - ca-certificates
          - curl

    - name: Ensure the keyrings directory exists
      file:
        path: /etc/apt/keyrings
        state: directory

    - name: Ensure the keyrings directory exists
      file:
        path: /etc/apt/keyrings
        state: directory

    - name: Import Kubernetes v1.34 GPG key
      shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.34/deb/Release.key \
        | sudo gpg --yes --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: Add Kubernetes apt repository (v1.34)
      copy:
        dest: /etc/apt/sources.list.d/kubernetes.list
        content: |
          deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.34/deb/ /

    - name: Update apt package
      apt:
        update_cache: yes

    - name: Install Kubernetes components v1.34.2
      apt:
        name:
          - kubelet=1.34.2-*
          - kubeadm=1.34.2-*
          - kubectl=1.34.2-*
        state: present
    
    - name: Hold kubelet
      ansible.builtin.dpkg_selections:
        name: kubelet
        selection: hold
    
    - name: Hold kubeadm
      ansible.builtin.dpkg_selections:
        name: kubeadm
        selection: hold

    - name: Hold kubectl
      ansible.builtin.dpkg_selections:
        name: kubectl
        selection: hold

    - name: Download and install Flannel
      ansible.builtin.get_url:
        url: https://github.com/flannel-io/flannel/releases/download/v0.27.4/flanneld-arm64
        dest: /usr/local/bin/flanneld
        owner: root
        group: root
        mode: '0755'

    - name: Create Flannel networks directory
      ansible.builtin.file:
        path: /var/lib/k8s/flannel/networks
        state: directory
        recurse: yes
        owner: root
        group: root
        mode: '0755'

    - name: Install open-iscsi on all nodes # sudo apt install open-iscsi
      ansible.builtin.apt:
        name: open-iscsi
        state: present
      become: yes

    - name: Reboot after installation is complete
      ansible.builtin.reboot:
        msg: "Rebooting after k8s prep is complete"
        connect_timeout: 5
        reboot_timeout: 300
        pre_reboot_delay: 0
        post_reboot_delay: 30

- name: Kubernetes control plane bootstrap with kube-vip workaround
  hosts: pi-1
  become: yes
  tasks:
    - name: Reset any previous Kubernetes installation
      ansible.builtin.command: kubeadm reset -f
      ignore_errors: yes

    - name: Remove old manifests
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      loop:
        - /etc/kubernetes/manifests/kube-apiserver.yaml
        - /etc/kubernetes/manifests/kube-controller-manager.yaml
        - /etc/kubernetes/manifests/kube-scheduler.yaml
        - /etc/kubernetes/manifests/etcd.yaml
      ignore_errors: yes
  
    - name: Copy local kube-vip.yaml to control-plane node
      ansible.builtin.copy:
        src: /Users/jenn/Projects/HomeLab/manifests/platform/kube-vip/kube-vip.yaml
        dest: /etc/kubernetes/manifests/kube-vip.yaml
        owner: root
        group: root
        mode: '0644'

    - name: Patch kube-vip manifest to use super-admin.conf
      ansible.builtin.replace:
        path: /etc/kubernetes/manifests/kube-vip.yaml
        regexp: 'path: /etc/kubernetes/admin.conf'
        replace: 'path: /etc/kubernetes/super-admin.conf'

    - name: Run kubeadm init
      ansible.builtin.command: >
        kubeadm init
        --kubernetes-version v1.34.2
        --control-plane-endpoint 192.168.0.201:6443
        --pod-network-cidr=10.244.0.0/16
        --upload-certs
      register: kubeadm_init
      ignore_errors: no

    - name: Patch kube-vip manifest back to admin.conf
      ansible.builtin.replace:
        path: /etc/kubernetes/manifests/kube-vip.yaml
        regexp: 'path: /etc/kubernetes/super-admin.conf'
        replace: 'path: /etc/kubernetes/admin.conf'

    - name: Wait for kube-vip pod to restart
      ansible.builtin.shell: |
        kubectl wait --for=condition=Ready pod/kube-vip-pi-1 -n kube-system
      retries: 5
      delay: 30
      register: kubevip_ready
      until: kubevip_ready.rc == 0

    - name: Generate kubeadm join command
      shell: kubeadm token create --print-join-command --kubeconfig /etc/kubernetes/admin.conf
      register: join_command_output
      become: true

    - name: Set kube_join_command fact
      set_fact:
        kube_join_command: "{{ join_command_output.stdout }}"

    - name: Debug join command
      debug:
        msg: "{{ kube_join_command }}"

- name: Join additional control-plane nodes
  hosts: additional-control-planes
  become: true
  tasks:
    - name: Copy local kube-vip.yaml to additional control-plane node
      ansible.builtin.copy:
        src: /Users/jenn/Projects/HomeLab/manifests/platform/kube-vip/kube-vip.yaml
        dest: /etc/kubernetes/manifests/kube-vip.yaml
        owner: root
        group: root
        mode: '0644'

    - name: Run kubeadm join
      shell: "{{ hostvars['pi-1'].kube_join_command }}"

- name: Label all 3 as control-plane nodes
  hosts: pi-1
  become: yes
  gather_facts: no
  tasks:
    - name: Label nodes as control-plane
      shell: |
        kubectl label node pi-1 node-role.kubernetes.io/control-plane= --overwrite
        kubectl label node pi-2 node-role.kubernetes.io/control-plane= --overwrite
        kubectl label node pi-3 node-role.kubernetes.io/control-plane= --overwrite
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: label_result

    - name: Show labeling result
      debug:
        msg: "{{ label_result.stdout_lines }}"

- name: Render flannel CNI yaml using kustomization locally
  hosts: localhost
  gather_facts: no
  tasks:
    - name: Generate from kustomization
      ansible.builtin.command: >
        kubectl kustomize /Users/jenn/Projects/HomeLab/manifests/platform/flannel/base
      register: flannel_yaml
      changed_when: false

- name: Copy CNI yaml and apply
  hosts: pi-1
  become: yes
  gather_facts: no
  tasks:
    - name: Ensure /tmp/flannel exists on the node
      ansible.builtin.file:
        path: /tmp/flannel
        state: directory
        mode: '0755'

    - name: Copy generated flannel YAML to node
      ansible.builtin.copy:
        content: "{{ hostvars['localhost'].flannel_yaml.stdout }}"
        dest: /tmp/flannel/flannel.yaml
        mode: '0644'

    - name: Apply flannel CNI
      ansible.builtin.shell: |
        kubectl apply -f /tmp/flannel/flannel.yaml
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: flannel_result
      retries: 5
      delay: 10
      until: flannel_result.rc == 0

    - name: Debug flannel apply result
      debug:
        var: flannel_result.stdout_lines

    - name: Wait until nodes are Ready to validate cni installation
      ansible.builtin.shell: |
        kubectl wait --for=condition=Ready nodes --all --timeout=300s
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: nodes_ready
      retries: 10
      delay: 15
      until: nodes_ready.rc == 0